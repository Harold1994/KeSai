{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split  \n",
    "import lightgbm as lgb\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始处理特征...\n",
      "['last_day_cut_max_day' 'launch_count' 'launch_day_mean' 'launch_day_max'\n",
      " 'launch_day_std' 'launch_day_cut_max_day' 'launch_day_diff_mean'\n",
      " 'launch_day_diff_min' 'launch_day_diff_std' 'activity_count'\n",
      " 'activity_day_max' 'activity_day_ske' 'activity_day_cut_max_day'\n",
      " '1_page_count' '3_page_count' '0_page_count_div_sum'\n",
      " '1_page_count_div_sum' '3_page_count_div_sum' '0_action_count'\n",
      " '0_action_count_div_sum' '1_action_count_div_sum' 'max_act_times_per_day'\n",
      " 'mean_hot_vid' 'mean_hot_auth' 'activity_day_diff_std'\n",
      " 'activity_day_diff_ske' 'activity_day_diff_kur']\n"
     ]
    }
   ],
   "source": [
    "print('开始处理特征...')\n",
    "train_path = 'data/train_and_test/train.csv'\n",
    "test_path = 'data/train_and_test/test.csv'\n",
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "used_feature = ['create_count', 'create_day_mean', 'create_day_max',\n",
    "       'create_day_min', 'create_day_std', 'create_day_var',\n",
    "       'last_day_cut_max_day', 'create_sub_register_x',\n",
    "       'max_create_times_per_day', 'create_day_diff_mean',\n",
    "       'create_day_diff_max', 'create_day_diff_min', 'create_day_diff_std',\n",
    "       'create_day_diff_var', 'device_type', 'register_type',\n",
    "       'register_day_cut_max_day', 'launch_count', 'launch_day_mean',\n",
    "       'launch_day_max', 'launch_day_min', 'launch_day_std', 'launch_day_var',\n",
    "       'launch_day_cut_max_day', 'create_sub_register_y',\n",
    "       'max_launch_times_per_day', 'launch_day_diff_mean',\n",
    "       'launch_day_diff_max', 'launch_day_diff_min', 'launch_day_diff_std',\n",
    "       'launch_day_diff_var', 'activity_count', 'activity_day_mean',\n",
    "       'activity_day_max', 'activity_day_min', 'activity_day_std',\n",
    "       'activity_day_var', 'activity_day_ske', 'activity_day_kur',\n",
    "       'activity_day_cut_max_day', 'create_sub_register', '0_page_count',\n",
    "       '1_page_count', '2_page_count', '3_page_count', '4_page_count',\n",
    "       '0_page_count_div_sum', '1_page_count_div_sum', '2_page_count_div_sum',\n",
    "       '3_page_count_div_sum', '4_page_count_div_sum', '0_action_count',\n",
    "       '1_action_count', '2_action_count', '3_action_count', '4_action_count',\n",
    "       '5_action_count', '0_action_count_div_sum', '1_action_count_div_sum',\n",
    "       '2_action_count_div_sum', '3_action_count_div_sum',\n",
    "       '4_action_count_div_sum', '5_action_count_div_sum',\n",
    "       'max_act_times_per_day', \n",
    "#                 'max_hot_vid', \n",
    "#                 'max_hot_auth',\n",
    "                'mean_hot_vid',\n",
    "       'mean_hot_auth',\n",
    "#                 'min_hot_vid',\n",
    "#                 'min_hot_auth',\n",
    "#                 'sum_hot_vid',\n",
    "#        'sum_hot_auth', \n",
    "                'activity_day_diff_mean', 'activity_day_diff_max',\n",
    "       'activity_day_diff_min', 'activity_day_diff_std',\n",
    "       'activity_day_diff_var', 'activity_day_diff_ske',\n",
    "       'activity_day_diff_kur', 'watch_self']\n",
    "used_feature = np.array(used_feature)\n",
    "importance_feature = [6, 17, 18, 19, 21, 23, 26, 28, 29, 31, 33, 37, 39, 42, 44, 46, 47, 49, 51, 57, 58, 63, 64, 65, 69, 71, 72]\n",
    "used_feature = used_feature[np.array(importance_feature)]\n",
    "print(used_feature)\n",
    "train_feature = train[used_feature]\n",
    "test_feature = test[used_feature]\n",
    "label = train['label']\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(train_feature, label, test_size=0.3,random_state=1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "载入数据......\n",
      "开始训练......\n",
      "[1]\tvalid_0's binary_logloss: 0.652302\tvalid_0's auc: 0.870989\n",
      "[2]\tvalid_0's binary_logloss: 0.619595\tvalid_0's auc: 0.873164\n",
      "[3]\tvalid_0's binary_logloss: 0.592538\tvalid_0's auc: 0.873422\n",
      "[4]\tvalid_0's binary_logloss: 0.569935\tvalid_0's auc: 0.873754\n",
      "[5]\tvalid_0's binary_logloss: 0.550973\tvalid_0's auc: 0.874023\n",
      "[6]\tvalid_0's binary_logloss: 0.534843\tvalid_0's auc: 0.874345\n",
      "[7]\tvalid_0's binary_logloss: 0.52118\tvalid_0's auc: 0.874555\n",
      "[8]\tvalid_0's binary_logloss: 0.50959\tvalid_0's auc: 0.874609\n",
      "[9]\tvalid_0's binary_logloss: 0.499457\tvalid_0's auc: 0.875264\n",
      "[10]\tvalid_0's binary_logloss: 0.490861\tvalid_0's auc: 0.875474\n",
      "[11]\tvalid_0's binary_logloss: 0.483439\tvalid_0's auc: 0.875724\n",
      "[12]\tvalid_0's binary_logloss: 0.47708\tvalid_0's auc: 0.875843\n",
      "[13]\tvalid_0's binary_logloss: 0.471601\tvalid_0's auc: 0.876053\n",
      "[14]\tvalid_0's binary_logloss: 0.466737\tvalid_0's auc: 0.876577\n",
      "[15]\tvalid_0's binary_logloss: 0.462623\tvalid_0's auc: 0.876754\n",
      "[16]\tvalid_0's binary_logloss: 0.459085\tvalid_0's auc: 0.876844\n",
      "[17]\tvalid_0's binary_logloss: 0.455976\tvalid_0's auc: 0.877037\n",
      "[18]\tvalid_0's binary_logloss: 0.453215\tvalid_0's auc: 0.877206\n",
      "[19]\tvalid_0's binary_logloss: 0.450804\tvalid_0's auc: 0.877387\n",
      "[20]\tvalid_0's binary_logloss: 0.448661\tvalid_0's auc: 0.877563\n",
      "[21]\tvalid_0's binary_logloss: 0.446639\tvalid_0's auc: 0.877815\n",
      "[22]\tvalid_0's binary_logloss: 0.444907\tvalid_0's auc: 0.878071\n",
      "[23]\tvalid_0's binary_logloss: 0.443475\tvalid_0's auc: 0.878229\n",
      "[24]\tvalid_0's binary_logloss: 0.442176\tvalid_0's auc: 0.878456\n",
      "[25]\tvalid_0's binary_logloss: 0.441045\tvalid_0's auc: 0.878669\n",
      "[26]\tvalid_0's binary_logloss: 0.44001\tvalid_0's auc: 0.878806\n",
      "[27]\tvalid_0's binary_logloss: 0.43907\tvalid_0's auc: 0.878953\n",
      "[28]\tvalid_0's binary_logloss: 0.438131\tvalid_0's auc: 0.879205\n",
      "[29]\tvalid_0's binary_logloss: 0.437324\tvalid_0's auc: 0.879372\n",
      "[30]\tvalid_0's binary_logloss: 0.436642\tvalid_0's auc: 0.879515\n",
      "[31]\tvalid_0's binary_logloss: 0.435867\tvalid_0's auc: 0.879743\n",
      "[32]\tvalid_0's binary_logloss: 0.435186\tvalid_0's auc: 0.879956\n",
      "[33]\tvalid_0's binary_logloss: 0.434602\tvalid_0's auc: 0.880173\n",
      "[34]\tvalid_0's binary_logloss: 0.433985\tvalid_0's auc: 0.880377\n",
      "[35]\tvalid_0's binary_logloss: 0.433475\tvalid_0's auc: 0.88048\n",
      "[36]\tvalid_0's binary_logloss: 0.432927\tvalid_0's auc: 0.880735\n",
      "[37]\tvalid_0's binary_logloss: 0.432378\tvalid_0's auc: 0.880956\n",
      "[38]\tvalid_0's binary_logloss: 0.431883\tvalid_0's auc: 0.881168\n",
      "[39]\tvalid_0's binary_logloss: 0.431411\tvalid_0's auc: 0.881302\n",
      "[40]\tvalid_0's binary_logloss: 0.430982\tvalid_0's auc: 0.881485\n",
      "[41]\tvalid_0's binary_logloss: 0.430411\tvalid_0's auc: 0.881725\n",
      "[42]\tvalid_0's binary_logloss: 0.430007\tvalid_0's auc: 0.881845\n",
      "[43]\tvalid_0's binary_logloss: 0.429617\tvalid_0's auc: 0.882035\n",
      "[44]\tvalid_0's binary_logloss: 0.429218\tvalid_0's auc: 0.882216\n",
      "[45]\tvalid_0's binary_logloss: 0.428829\tvalid_0's auc: 0.882429\n",
      "[46]\tvalid_0's binary_logloss: 0.428425\tvalid_0's auc: 0.882596\n",
      "[47]\tvalid_0's binary_logloss: 0.42799\tvalid_0's auc: 0.882762\n",
      "[48]\tvalid_0's binary_logloss: 0.42767\tvalid_0's auc: 0.882911\n",
      "[49]\tvalid_0's binary_logloss: 0.427298\tvalid_0's auc: 0.883109\n",
      "[50]\tvalid_0's binary_logloss: 0.426827\tvalid_0's auc: 0.88331\n",
      "[51]\tvalid_0's binary_logloss: 0.426455\tvalid_0's auc: 0.883515\n",
      "[52]\tvalid_0's binary_logloss: 0.426131\tvalid_0's auc: 0.883732\n",
      "[53]\tvalid_0's binary_logloss: 0.425649\tvalid_0's auc: 0.883937\n",
      "[54]\tvalid_0's binary_logloss: 0.425335\tvalid_0's auc: 0.884114\n",
      "[55]\tvalid_0's binary_logloss: 0.424889\tvalid_0's auc: 0.884404\n",
      "[56]\tvalid_0's binary_logloss: 0.424586\tvalid_0's auc: 0.884547\n",
      "[57]\tvalid_0's binary_logloss: 0.424262\tvalid_0's auc: 0.884739\n",
      "[58]\tvalid_0's binary_logloss: 0.423967\tvalid_0's auc: 0.884896\n",
      "[59]\tvalid_0's binary_logloss: 0.42369\tvalid_0's auc: 0.885048\n",
      "[60]\tvalid_0's binary_logloss: 0.423394\tvalid_0's auc: 0.885162\n",
      "结果：0.813259082471493\n",
      "特征重要性：[59, 124, 47, 42, 113, 198, 103, 41, 98, 39, 59, 54, 47, 29, 46, 30, 58, 41, 49, 40, 59, 60, 85, 97, 68, 57, 57]\n"
     ]
    }
   ],
   "source": [
    "print('载入数据......')\n",
    "lgb_train = lgb.Dataset(train_feature, label)\n",
    "lgb_eval = lgb.Dataset(X_test, Y_test, reference=lgb_train)\n",
    "\n",
    "\n",
    "print('开始训练......')\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'auc', 'binary_logloss'},\n",
    "}\n",
    "# params = {\n",
    "#     'task': 'train',\n",
    "#     'boosting_type': 'gbdt',\n",
    "#     'objective': 'regression',\n",
    "#     'metric': {'l2'}\n",
    "# }\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=60,\n",
    "                valid_sets=lgb_eval\n",
    "                )\n",
    "gbm.save_model('model/lgb_model.txt')\n",
    "\n",
    "temp = gbm.predict(X_test)\n",
    "temp[temp>=0.42]=1\n",
    "temp[temp<0.42]= 0\n",
    "print('结果：' + str(sklearn.metrics.f1_score(Y_test, temp)))\n",
    "print('特征重要性：'+ str(list(gbm.feature_importance())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "为1的个数：0\n",
      "为0的个数：0\n"
     ]
    }
   ],
   "source": [
    "pre = gbm.predict(test_feature)\n",
    "df_result = pd.DataFrame()\n",
    "df_result['user_id'] = test['user_id']\n",
    "df_result['result'] = pre\n",
    "df_result.to_csv('result/lgb_result.csv', index=False)\n",
    "pre[pre >= 0.44]=1\n",
    "pre[pre < 0.44]=0\n",
    "pre = map(int,pre)\n",
    "print('为1的个数：' + str(len(np.where(np.array(pre)==1)[0])))\n",
    "print('为0的个数：' + str(len(np.where(np.array(pre)==0)[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23569\n"
     ]
    }
   ],
   "source": [
    "lgb = pd.read_csv('result/lgb_result.csv')\n",
    "res = lgb[lgb['result'] >= 0.44]\n",
    "print(len(res))\n",
    "del res['result']\n",
    "res.to_csv('result2/dealed_result06128164.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([12, 21, 13, 10, 10, 0, 26, 14, 1, 10, 9, 6, 6, 0, 0, 0, 0, 125, 29, 43, 14, 88, 3, 183, 18, 0, 103, 16, 30, 90, 7, 27, 18, 45, 10, 19, 2, 45, 0, 42, 0, 21, 30, 19, 45, 6, 27, 41, 16, 35, 17, 32, 22, 6, 3, 0, 0, 37, 43, 25, 14, 0, 0, 41, 56, 73, 23, 5, 14, 36, 4, 45, 59, 0])\n",
    "a.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 17, 18, 19, 21, 23, 26, 28, 29, 31, 33, 37, 39, 42, 44, 46, 47, 49, 51, 57, 58, 63, 64, 65, 69, 71, 72]\n"
     ]
    }
   ],
   "source": [
    "b = []\n",
    "for i in range(0, a.size-1):\n",
    "    if a[i] > 25:\n",
    "        b.append(i)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression   \n",
    "  \n",
    "classifier = LogisticRegression()  # 使用类，参数全是默认的  \n",
    "classifier.fit(X_train,X_test)  # 训练数据来学习，不需要返回值  \n",
    "classifier.predict(test_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-18d0a447c62c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    885\u001b[0m         \"\"\"\n\u001b[1;32m    886\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minertia_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36m_check_fit_data\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    856\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_fit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;34m\"\"\"Verify that the number of samples given is larger than k\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 858\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    859\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             raise ValueError(\"n_samples=%d should be >= n_clusters=%d\" % (\n",
      "\u001b[0;32m~/Documents/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 44\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_feature, label, test_size=0.2, random_state=0)\n",
    "clf = KMeans(n_clusters=2,max_iter=300,n_init=10)\n",
    "clf.fit(X_train)\n",
    "ypred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
